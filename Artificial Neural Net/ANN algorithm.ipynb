{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIYZUpYKbhUD"
   },
   "source": [
    "# Artificial Neural Net Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Algorithm mimics the an Artificial Neural Network Model. The algorithm has been implemented using the logics behind the working of an Artificial Neural Network. The Algorithm utilizes basic and prebuilt Python libraries to implement and simulate a 3 layer Artificial Neural Net. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOJTpx1CIni8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from numpy.random import RandomState as random_state_\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7P9pH1gphrQ"
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use drug_activity.csv file for training and testing the Model. The dataset is a Sparse Matrix containing 800 rows and 6062 columns, each row representing a certain molecule and each column representing a certain feature of the molecules. \n",
    "\n",
    "The first column of the dataset contains the labels for whether the molecule is active (1) or inactive (0) when it comes to making drugs. Active molecules are good for drug making. \n",
    "\n",
    "The dataset is imbalanced however; it contains only 78 Active molecules. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itEALSm-IABs",
    "outputId": "a9472414-967b-4212-da21-3f50cfc09144"
   },
   "outputs": [],
   "source": [
    "# importing dataset to Pandas dataframe\n",
    "train_df = pd.read_csv('drug_activity.csv', sep='delimiter', header=None)\n",
    "\n",
    "# separating comma separated values \n",
    "train_df = train_df[0].str.split(\",\", expand = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "6I60j9fD0zJa",
    "outputId": "5806f381-ecf2-49e7-9a0b-8cad090b62a4"
   },
   "outputs": [],
   "source": [
    "# preview 10 random Molecules from the dataframe\n",
    "train_df.sample(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of Label Counts (Active and Inactive Molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label value counts \n",
    "train_df[0].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data preparations and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WGMGgEDkIGL7"
   },
   "outputs": [],
   "source": [
    "# dropping Nan/None values\n",
    "train_df = train_df.fillna(0)\n",
    "\n",
    "# truncating dataframe. selecting only relevant features. dropping features with 0s\n",
    "train_df = train_df.iloc[:,:500]\n",
    "\n",
    "# convert all columns of DataFrame\n",
    "train_df = train_df.apply(pd.to_numeric) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "xSCW5kpruVJb",
    "outputId": "dd35d0fa-124a-4a81-c937-d87f2f61921c"
   },
   "outputs": [],
   "source": [
    "train_df.sample(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting features and attributes (X and Y labels) for our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1nRuEgRILv9"
   },
   "outputs": [],
   "source": [
    "# first prepare arrays from train data \n",
    "train_array = train_df.values\n",
    "\n",
    "# features\n",
    "features_ = train_array[:,1:]\n",
    "\n",
    "# attributes\n",
    "attributes_ = train_array[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Oversampling to handle the imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZILiW_5IXwZ"
   },
   "outputs": [],
   "source": [
    "# library to use for Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler as sm\n",
    "\n",
    "# oversampling class object with random state\n",
    "oversample = sm(random_state = 100)\n",
    "\n",
    "# Oversampling the data with the object\n",
    "features, attributes = oversample.fit_resample(features_,attributes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4wWt01PrFJH"
   },
   "source": [
    "###### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mI1hJy0lJzFy"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, attributes, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66g038cJjuvC"
   },
   "source": [
    "###### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ESrar9jgZGT"
   },
   "outputs": [],
   "source": [
    "# convert y_train and y_test to array for effective calculations\n",
    "y_train = np.array(y_train, dtype=np.int64, order='C')\n",
    "y_test = np.asarray(y_test, dtype=np.int64, order='C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syUJzS0MwxIX"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# preprocessing X_train and X_test\n",
    "X_train = preprocessing.scale(X_train).T\n",
    "X_test = preprocessing.scale(X_test).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsMY9NzjI3YM"
   },
   "outputs": [],
   "source": [
    "# some initializations for calculations \n",
    "rs_ = random_state_(1234567890)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class algorithm:\n",
    "\n",
    "    # initialize the model class objects\n",
    "    def __init__(self, X_train, y_train, layers):\n",
    "        \n",
    "        self.layers = layers\n",
    "        \n",
    "        self.X = X_train\n",
    "        self.Y = np.array(y_train).reshape(1, y_train.shape[0])\n",
    "        \n",
    "        self.L = len(layers) - 1\n",
    "        \n",
    "        self.cache_ = {}\n",
    "        self.grads_ = {}\n",
    "        self.params_ = {}\n",
    "        \n",
    "        layers[0] = (X_train.shape[0], None)\n",
    "        \n",
    "        k = len(layers)\n",
    "\n",
    "        # initiliaze parameters\n",
    "        for i in range(1, k):\n",
    "            \n",
    "            previous_layer = layers[i-1][0]\n",
    "            current_layer = layers[i][0]\n",
    "            \n",
    "            self.params_['W' + str(i)] = rs_.randn(current_layer, previous_layer) * np.sqrt(2 / previous_layer)\n",
    "            self.params_['b' + str(i)] = np.zeros((current_layer, 1))\n",
    "\n",
    "\n",
    "    def _forward_(self):\n",
    "        \n",
    "        Z = self.params_['W1'].dot(self.X) + self.params_['b1']\n",
    "        \n",
    "        A = functions.activate(Z, layers[1][1])\n",
    "        \n",
    "        self.cache_['Z1'] = Z\n",
    "        self.cache_['A1'] = A\n",
    "         \n",
    "        k = len(self.layers)\n",
    "        \n",
    "        for i in range(2, k):\n",
    "            \n",
    "            a_previous = A\n",
    "            \n",
    "            Z = self.params_['W' + str(i)].dot(a_previous) + self.params_['b' + str(i)]\n",
    "            \n",
    "            A = functions.activate(Z, layers[i][1])\n",
    "            \n",
    "            self.cache_['Z' + str(i)] = A\n",
    "            self.cache_['A' + str(i)] = Z\n",
    "            \n",
    "            \n",
    "         \n",
    "\n",
    "    def _backward_(self, lambd):\n",
    "        \n",
    "        dA_ = 0\n",
    "        \n",
    "        A = self.cache_['A' + str(self.L)]\n",
    "        \n",
    "        if self.layers[self.L][1] == 'sigmoid': \n",
    "            \n",
    "            dA_ = -np.divide(self.Y, A) - np.divide(1 - self.Y, 1 - A)\n",
    "        \n",
    "        k = self.L + 1\n",
    "        \n",
    "        for i in reversed(range(1, k)):\n",
    "            \n",
    "            a_previous = np.array([])\n",
    "            \n",
    "            scalar = self.X.shape[1]\n",
    "            \n",
    "            if i == 1:\n",
    "                a_previous = self.X\n",
    "                \n",
    "            else : \n",
    "                a_previous = self.cache_['A' + str(i-1)]\n",
    "                \n",
    "            # calculate the gradients\n",
    "            dZ_ = dA_ * functions.d_activate(self.cache_['Z' + str(i)], layers[i][1])\n",
    "            dA_ = np.dot(self.params_['W' + str(i)].T, dZ_)\n",
    "            \n",
    "            # store gradients\n",
    "            self.grads_['dW' + str(i)] = (1/scalar) * dZ_.dot(a_previous.T) + (lambd/scalar)*self.params_['W' + str(i)]\n",
    "            self.grads_['db' + str(i)] = (1/scalar) * np.sum(dZ_, axis=1, keepdims=True)\n",
    "\n",
    "            \n",
    "            \n",
    "    # update model parameters\n",
    "    def _params_(self, alpha):\n",
    "        \n",
    "        k = self.L+1\n",
    "        \n",
    "        for i in range(1, k):\n",
    "            \n",
    "            self.params_['W' + str(i)] = self.params_['W' + str(i)] - alpha * self.grads_['dW' + str(i)]\n",
    "            self.params_['b' + str(i)] = self.params_['b' + str(i)] - alpha * self.grads_['db' + str(i)]\n",
    "            \n",
    "            \n",
    "            \n",
    "    # calculate cost\n",
    "    def _cost_(self, lambd):\n",
    "        \n",
    "        A = self.cache_['A' + str(self.L)]\n",
    "        \n",
    "        m = self.Y.shape[1]\n",
    "        \n",
    "        # regularization sum\n",
    "        r_sum = 0\n",
    "        \n",
    "        k = len(self.layers) \n",
    "        \n",
    "        for i in range(1, k):\n",
    "            \n",
    "            r_sum += np.sum(np.square(self.params_['W' + str(i)]))\n",
    "    \n",
    "        \n",
    "        cost = - (1/m) * ( np.dot(self.Y, A.T) + np.dot(1 - self.Y, 1 - A.T)) + (lambd/(2*m)) * r_sum\n",
    "        \n",
    "        return np.squeeze(cost)   \n",
    "            \n",
    "    \n",
    "    # train the algorithm\n",
    "    def train(self, alpha, iterations, lambd, cost_display=False):\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            \n",
    "            # calling forward function to iterate through layer\n",
    "            self._forward_()\n",
    "            \n",
    "            # calling backward function\n",
    "            self._backward_(lambd)\n",
    "            \n",
    "            # calling params function to update parameters\n",
    "            self._params_(alpha)\n",
    "            \n",
    "            self._backward_(lambd)\n",
    "            self._params_(alpha)\n",
    "            \n",
    "        # display cost \n",
    "        if cost_display == True:\n",
    "            # calling costs function to calculate cost\n",
    "            cost = self._cost_(lambd)\n",
    "            print('-----------------------------------------------------------')\n",
    "            print('Cost: --')\n",
    "            print(f'{cost}')\n",
    "                \n",
    "\n",
    "            \n",
    "                \n",
    "\n",
    "    # function to handle predictions\n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        Z = self.params_['W1'].dot(X_test) + self.params_['b1']\n",
    "        \n",
    "        A = functions.activate(Z, layers[1][1])\n",
    "        \n",
    "        k = len(self.layers)\n",
    "        \n",
    "        for i in range(2,k):\n",
    "            \n",
    "            a_previous = A\n",
    "            \n",
    "            Z = self.params_['W' + str(i)].dot(a_previous) + self.params_['b' + str(i)]\n",
    "            \n",
    "            A = functions.activate(Z, layers[i][1])\n",
    "            \n",
    "        return np.where(A > .5, 1, 0)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model built from the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize 3 layers for the Model\n",
    "layers = {1: (5, 'relu'), 2: (15, 'relu'), 3: (1, 'sigmoid')}\n",
    "\n",
    "# initializing the Model \n",
    "model = algorithm(X_train, y_train, layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Classification Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model from Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qr1miC0VW20T"
   },
   "outputs": [],
   "source": [
    "# train model alpha value (.05), iterations (1000) and lambda value (1)\n",
    "\n",
    "toc = time.time()\n",
    "model.train(.005, 1000, 1, cost_display=True)\n",
    "tic = time.time()\n",
    "\n",
    "# time taken for training in seconds\n",
    "print('-----------------------------------------------------------')\n",
    "print(f'Time taken for training model (s): {tic - toc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Model for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# predictions from Model\n",
    "toc = time.time()\n",
    "y_pred = model.predict(X_test)\n",
    "tic = time.time()\n",
    "\n",
    "# time taken for prediction in seconds\n",
    "print('-----------------------------------------------------------')\n",
    "print(f'Time taken for prediction (s): {tic - toc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfomance of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute perfomance scores\n",
    "accuracy_score_ = accuracy_score(y_test, y_pred)\n",
    "confusion_matrix_ = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Ouput Performance of Algorithm\n",
    "print('-----------------------------------------------------------')\n",
    "print('Perfomance of the Model in Drug Molecules Classification')\n",
    "print('-----------------------------------------------------------')\n",
    "print(f'Accuracy Score: {accuracy_score_}')\n",
    "print('-----------------------------------------------------------')\n",
    "print('Confusion Matrix:')\n",
    "print('-----------------')\n",
    "print(f'{confusion_matrix_}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
